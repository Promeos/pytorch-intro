{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: _What_ is PyTorch?\n",
    "---\n",
    "[Source](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py) for this tutorial\n",
    "\n",
    "<br></br>\n",
    "<dl>\n",
    "    <dt>PyTorch</dt>\n",
    "    <dd>is a Python-based computing package</dd>\n",
    "</dl>\n",
    "\n",
    "- A programming language that uses the power of GPU's to speed up calculations.\n",
    "> I don't have an <font color=green>NVIDIA GPU</font> at the moment but I'll press on.\n",
    ">\n",
    "> I'll rent one here -> [NVIDIA GPU in the clouds above](https://cloud.google.com/)\n",
    "- It's flexible and F.A.S.T.\n",
    "    > `Python` + \"...dang it's so fast it lit a <font color=red>_Torch_</font>\" == __`PyTorch`__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "### Tensors\n",
    "\n",
    "As I discovered in the first tutorial, `PyTorch` is similar to` NumPy`. Again, `PyTorch` uses __GPU's__, which makes it faster than `NumPy` for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"An __uninitialized matrix__ is declared, but _does not_ contain __definite known values__ before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\"\n",
    "\n",
    "### Creating an empty Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.4515e-05,  6.2358e-43, -8.4498e-05],\n",
      "        [ 6.2358e-43, -8.4498e-05,  6.2358e-43],\n",
      "        [-8.4498e-05,  6.2358e-43, -8.4501e-05],\n",
      "        [ 6.2358e-43, -8.4501e-05,  6.2358e-43],\n",
      "        [-8.4503e-05,  6.2358e-43, -8.4503e-05]])\n"
     ]
    }
   ],
   "source": [
    "# Creating an 'uninitialized matrix' with `tensor.empty()`\n",
    "# So does it not have values?\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9999, 1.0000, 0.9999],\n",
       "        [1.0000, 0.9999, 1.0000],\n",
       "        [0.9999, 1.0000, 0.9999],\n",
       "        [1.0000, 0.9999, 1.0000],\n",
       "        [0.9999, 1.0000, 0.9999]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interesting, the \"values\" (0's) that were placed in the empty tensor matrix\n",
    "# changed to actual values once operated on...\n",
    "x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Random Martrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8794e-01, -1.7331e+00, -3.6498e-01,  4.5611e-01, -3.8536e-01,\n",
      "         -7.0319e-01,  4.8289e-01],\n",
      "        [ 3.1298e-01,  2.4829e-01, -3.2561e-01,  2.2413e+00,  6.0704e-01,\n",
      "          3.1962e-01, -7.1013e-01],\n",
      "        [ 2.4409e+00,  1.8083e+00, -9.6987e-01,  5.1501e-01, -1.2459e+00,\n",
      "          9.6192e-01, -1.9946e-03],\n",
      "        [-5.9124e-01, -5.7221e-01, -1.4373e+00, -2.5147e+00, -6.4413e-01,\n",
      "          1.6397e+00,  2.6878e-01],\n",
      "        [-1.8641e+00,  8.2970e-01, -1.3285e+00, -1.1605e+00, -9.3258e-01,\n",
      "          4.4304e-01,  1.3145e+00]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 7, dtype=torch.float64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Matrix of Zeros and Ones\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 5, dtype=torch.long)  # 64-bit integer (signed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 5, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, 5, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, 5, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.+0.j, 1.+0.j, 1.+0.j],\n",
       "        [1.+0.j, 1.+0.j, 1.+0.j],\n",
       "        [1.+0.j, 1.+0.j, 1.+0.j]], dtype=torch.complex128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3, 3, dtype=torch.cdouble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "PyTorch tensors are unable to infer True as 1 and False as 0's\n",
    "``` python\n",
    "torch.ones(5, 5, dtype=torch.bool).mean()\n",
    "```\n",
    "<font color=red>RuntimeError</font>: Can only calculate the mean of floating types. Got Bool instead.\n",
    "\n",
    "\n",
    "### Create a Tensor from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tensor using NumPy to generate data\n",
    "x = torch.tensor(np.random.randint(1, 11, size=(10, 10)))\n",
    "\n",
    "# Create a Tensor using PyTorch built in method `.randint()`\n",
    "y = torch.randint(1, 11, size=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  8,  2,  1,  1,  6,  2,  2,  5,  2],\n",
       "        [ 1,  3,  6,  8,  1,  5,  2,  9,  3,  7],\n",
       "        [ 6,  1,  5,  9,  8,  7,  7,  8,  2,  9],\n",
       "        [ 3,  3,  2,  2,  5,  3,  8,  9, 10, 10],\n",
       "        [10, 10,  9,  4, 10,  7,  3,  5,  8,  6],\n",
       "        [10,  4,  7,  7,  5,  1,  4,  1,  4,  7],\n",
       "        [ 4,  3,  8, 10,  6,  9,  9,  6,  3,  2],\n",
       "        [10,  7,  4,  8,  8,  6,  7,  2,  6,  3],\n",
       "        [ 5,  6,  2,  2,  6,  8,  8,  5,  9,  1],\n",
       "        [ 1,  5,  3,  3,  2,  6,  1, 10, 10, 10]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.dtype)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  9,  6,  9,  6,  1,  1,  1,  2,  6],\n",
       "        [ 9,  4,  5,  7, 10, 10,  8, 10,  8,  5],\n",
       "        [ 7,  9,  4,  1,  2,  3,  8,  3,  5,  1],\n",
       "        [ 9,  7,  2,  8,  1,  8,  3,  5,  1,  1],\n",
       "        [ 8,  2,  8,  3,  9,  6,  5,  1,  7, 10],\n",
       "        [10,  1,  9,  5,  4,  5,  5,  4,  2,  4],\n",
       "        [ 3,  6,  8,  6,  1,  8,  8,  3,  5, 10],\n",
       "        [ 5,  9,  9,  9,  7,  4,  6,  1,  2,  8],\n",
       "        [ 1,  9,  7,  7,  1,  2,  9, 10,  2,  2],\n",
       "        [10,  3,  8,  4,  1, 10,  1,  3,  6,  9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.dtype)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Tensor based on an existing Tensor\n",
    "#### Creating Tensors with new dimensions, dtypes, and requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .new_*() methods, we can create new Tensors!\n",
    "# If needed, we can also change the dtype\n",
    "\n",
    "new_x1 = x.new_ones(3, 3)\n",
    "new_x2 = x.new_ones(5, 5, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_x1.dtype)\n",
    "new_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_x2.dtype)\n",
    "new_x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newly created Tensors do not have `requires_grad=True` because:\n",
    "1. The original Tensor it was created from did not have `requires_grad=True`\n",
    "2. When creating the Tensor from an exisiting Tensor, __WE__ did not specifiy `requires_grad=True`.\n",
    "\n",
    ">__REMINDER__! `requires_grad=True` can only be set on Tensors of `dtype=float`!\n",
    "> Example:\n",
    "> ``` python\n",
    "> # new_x1.dtype >>> torch.int64\n",
    "new_x1.requires_grad_()\n",
    "> ```\n",
    "> If you try to set `requires_grad=True` on a Tensor of dtype `torch.int64` you'll get the following error.\n",
    ">\n",
    "> <font color=red>RuntimeError</font>:\n",
    ">```python \n",
    "Only Tensors of float point dtype can require gradients\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(new_x1.requires_grad)\n",
    "print(new_x2.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print(new_x1.requires_grad_())\n",
    "\n",
    "# Now our new tensor has memory.\n",
    "print(new_x2.requires_grad_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensors from Tensors using the SAME dimensions, different dtypes, requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x was initialized with the data type `int`\n",
    "x_new_full = x.new_full(x.shape, 10, dtype=float).requires_grad_()\n",
    "y_new_full = x.new_full(x.size(), 10, dtype=float).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.size())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "torch.Size([10, 10])\n",
      "torch.float64\n",
      "\n",
      "y\n",
      "torch.Size([10, 10])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print('x')\n",
    "print(x_new_full.shape)\n",
    "print(x_new_full.dtype)\n",
    "\n",
    "print('\\ny')\n",
    "print(y_new_full.shape)\n",
    "print(y_new_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3550, 0.9659, 1.1494],\n",
      "        [1.0178, 1.1675, 1.2050],\n",
      "        [0.1595, 1.9058, 0.9664],\n",
      "        [0.2994, 0.5133, 0.1732],\n",
      "        [1.1894, 0.8084, 0.6810]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3550, 0.9659, 1.1494],\n",
      "        [1.0178, 1.1675, 1.2050],\n",
      "        [0.1595, 1.9058, 0.9664],\n",
      "        [0.2994, 0.5133, 0.1732],\n",
      "        [1.1894, 0.8084, 0.6810]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3550, 0.9659, 1.1494],\n",
      "        [1.0178, 1.1675, 1.2050],\n",
      "        [0.1595, 1.9058, 0.9664],\n",
      "        [0.2994, 0.5133, 0.1732],\n",
      "        [1.1894, 0.8084, 0.6810]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3550, 0.9659, 1.1494],\n",
       "        [1.0178, 1.1675, 1.2050],\n",
       "        [0.1595, 1.9058, 0.9664],\n",
       "        [0.2994, 0.5133, 0.1732],\n",
       "        [1.1894, 0.8084, 0.6810]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3550, 0.9659, 1.1494],\n",
       "        [1.0178, 1.1675, 1.2050],\n",
       "        [0.1595, 1.9058, 0.9664],\n",
       "        [0.2994, 0.5133, 0.1732],\n",
       "        [1.1894, 0.8084, 0.6810]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.shape, z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(1, 11, size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  8,  7],\n",
      "        [ 9,  8,  6],\n",
      "        [ 1,  2, 10]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "x[0,0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Bridge\n",
    "---\n",
    "Converting a Torch Tensor to a NumPy array and vice a versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a NumPy Array to Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9,  9,  8],\n",
      "        [10,  9,  7],\n",
      "        [ 2,  3, 11]], device='cuda:0')\n",
      "tensor([[ 9.,  9.,  8.],\n",
      "        [10.,  9.,  7.],\n",
      "        [ 2.,  3., 11.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Autograd: Automatic Differentiation\n",
    "---\n",
    "[Source](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) of this tutorial\n",
    "\n",
    "PyTorch functions for auto-gradient implementation:\n",
    "1. `torch.tensor`\n",
    "1. `torch.tensor.requires_grad_()`\n",
    "1. `torch.tensor.backward()`\n",
    "1. `tensor.detach()`\n",
    "1. `tensor.grad_fn`\n",
    "\n",
    "The `autograd` package is the cornerstone to all neural networks in `PyTorch`.\n",
    "- `autograd` provides automatic differentiation fot all operations on all tensors. MEMORY\n",
    "- Backpropagation is defined by how your code is excuted.\n",
    "- Every iteration can be different.\n",
    "\n",
    "## Tensor\n",
    "---\n",
    "__`torch.tensor`__ is the fundamental building block in PyTorch.\n",
    "> If `requires_grad=True`, the tensor begins to \"remember\" all operations on it.\n",
    ">\n",
    "> When you call `.backward()` on a `torch.tensor` object that has the attribute `requires_grad=True`, all gradients are computed automatically.\n",
    "    > - The gradient is stored in the `.grad` attribute.\n",
    "\n",
    "To remove a tensor's \"memory\" use `.detach()` to detach it from the computational history. Detach it from its \"experience\". The tensor will also not be able to \"remember\" any future computations performed on it.\n",
    "\n",
    "To prevent a torch from having memory, wrap the code block with:\n",
    "> `with torch.no_grad():`\n",
    "\n",
    "Note: Useful when evaluating a model because the model may have \"trainable parameters\" with `requires_grad=True` and we __don't need the gradients__.\n",
    "\n",
    "`Function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=float, requires_grad=True)\n",
    "y = torch.tensor([1, 2, 3], dtype=float, requires_grad=True)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True)\n",
      "tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Notice that when we create a new tensor by adding two tensors that have `requires_grad`=True,\n",
    "# The new tensor `z` has memory of how it was created grad_fn=<AddBackward0>.\n",
    "# It knows it was created by addition!\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tensor by mulitplying two existing tensors and a value/scaler\n",
    "a = z * z * 10\n",
    "a_scalar = a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 40., 160., 360.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(186.6667, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Reminder: Tensors can only contain float dtypes.\n",
    "\n",
    "# Similarly, tensor `a` knows that it was created grad_fn=<MulBackward0> == multiplication!\n",
    "print(a)\n",
    "\n",
    "# We'll use a_scalar in the next section gradients\n",
    "print(a_scalar)  # Interesting, this tensor remember the function used on it: grad_fn=<MeanBackward0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(2, 3)\n",
    "b = ((b*10) / (b-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does tensor `b` have autograd enabled? False\n"
     ]
    }
   ],
   "source": [
    "# Reminder: When you create new tensors, you must explicity set requires_grad=True\n",
    "\n",
    "# This tensor does not have autograd enabled. Tensors created from b will not have autograd enabled.\n",
    "print(f\"Does tensor `b` have autograd enabled? {b.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.2595,   4.6142,   5.6527],\n",
       "        [  0.5306,  49.7864, 133.1301]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .requires_grad_() function to add backpropagation to the tensor `b`\n",
    "# Using .requires_grad_(True) modifies the tensor inplace, giving it memory.\n",
    "b.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x000001BDB9B5F2B0>\n",
      "None\n",
      "<SumBackward0 object at 0x000001BDB9B5F2B0>\n"
     ]
    }
   ],
   "source": [
    "c = (a * b).sum()\n",
    "print(a.grad_fn)  # created from: z * z * 10\n",
    "print(b.grad_fn)  # A tensor created from scratch will not have memory. Only the ability to memorize.\n",
    "print(c.grad_fn)  # created from: (a * b).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My first backpropagation!\n",
    "a_scalar.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor `x` and tensor `y` are considered leaves, or leaf individually. These two tensors are the origin of `a_scalar`.\n",
    "When backpropagation is executed, the gradient calculations stop at `x` and `y`.\n",
    "\n",
    "`a_scaler` ----Backprop----> `a` ----Backprop----> `z` ----Backprop----> __`x` + `y`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.3333, 26.6667, 40.0000], dtype=torch.float64)\n",
      "tensor([13.3333, 26.6667, 40.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Tensor `z` is called a __non-leaf__. Similar to decision tree leafs/pure leafs, this tensor is considered a node. \n",
    "\n",
    "```python\n",
    "print(z.grad)\n",
    "```\n",
    "\n",
    "<div class='alert alert-block alert-danger'>UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
    "This is separate from the ipykernel package so we can avoid doing imports until </div>\n",
    "  \n",
    "### Example of vector-Jacobian product  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  -58.6070,  -586.2420, -1183.5730], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Reminder x2: When creating a new tensor, you must explicitly set requires_grad=True\n",
    "# To perform backprop and give the tensor memory.\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:  # x.data returns the values the tensor object with scalar values\n",
    "    y *= 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
     ]
    }
   ],
   "source": [
    "x.data.norm()\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop autograd\n",
    "---\n",
    "- `with torch.no_grad():` code block\n",
    "- `.requires_grad_(False)`\n",
    "- `.detach()`\n",
    "\n",
    "#### `with torch.no_grad():` code block\n",
    "- Wrapping a tensor that was created with requires_grad=True will not be able to pass its __memory abilities__ to new tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does tensor `x` have autograd enabled?\n",
      "True\n",
      "\n",
      "What about a new tensor? Would it have autograd enabled it was created from tensor `x`?\n",
      "True\n",
      "\n",
      "Does tensor `x` have auto_grad enabled now that it's in a torch.no_grad() code block?\n",
      "True\n",
      "\n",
      "What about the new tensor? Would it have auto grad enabled now that it's inside a torch.no_grad(): code block?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Wrapping a tensor that has requires_grad=True inside a code block\n",
    "# That removes the tensors memory as long as it's in the code block\n",
    "\n",
    "# As we're learning, we know that tensors created from tensors that have requires_grad=True will\n",
    "# pass their memory ability to the new tensor\n",
    "print(f\"Does tensor `x` have autograd enabled?\")\n",
    "print(x.requires_grad)\n",
    "print(\"\\nWhat about a new tensor? Would it have autograd enabled it was created from tensor `x`?\")\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"\\nDoes tensor `x` have auto_grad enabled now that it's in a torch.no_grad() code block?\")\n",
    "    print(x.requires_grad)\n",
    "    print(\"\\nWhat about the new tensor? Would it have auto grad enabled now that it's inside a torch.no_grad(): code block?\")\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.requires_grad_(False)`\n",
    "- Most explicit way to remove a tensors' memory is by using `tensor_name.requires_grad_(False)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does tensor `x` have auto_grad enabled? True\n",
      "\n",
      "What about now? False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Does tensor `x` have auto_grad enabled? {x.requires_grad}\")\n",
    "x.requires_grad_(False)\n",
    "print()\n",
    "print(f\"What about now? {x.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.detach`\n",
    "- Use `.detach()` to remove autograd but keep contents of tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does tensor `x` have auto_grad enabled? True\n",
      "Does tensor `y` have auto_grad enabled? False\n",
      "\n",
      "Is tensor `x` equal to tensor `y`?\n",
      "tensor(True)\n",
      "tensor([True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# Set tensor `x` with requires_grad=True to walkthrough using detach()\n",
    "x.requires_grad_(True)\n",
    "\n",
    "print(f\"Does tensor `x` have auto_grad enabled? {x.requires_grad}\")\n",
    "\n",
    "# Create a new tensor from `x` that does not have requires_grad=True. Remove its memory.\n",
    "y = x.detach()\n",
    "\n",
    "print(f\"Does tensor `y` have auto_grad enabled? {y.requires_grad}\", end='\\n\\n')\n",
    "\n",
    "# Although `y` does not have autograd enabled, both tensors contain the same values\n",
    "print(\"Is tensor `x` equal to tensor `y`?\")\n",
    "print(x.eq(y).all())\n",
    "\n",
    "# Another proof of equality\n",
    "print(x==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Neural Networks\n",
    "\n",
    "Source of [tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
    "\n",
    "Neural networks are created with the `torch.nn` package. Neural networks depend on autograd to define models and differentiate them!\n",
    "\n",
    "`nn.Module` contains layers and method `forward()` (feed forward? Yes!) that returns the output.\n",
    "\n",
    "Simple feed-forward networks takes an input, feeds it/pushes it through several layers, and returns an output.\n",
    "\n",
    "Standard Operating Procedure to train neural networks:\n",
    "1. Define the neural network with learnable parameters(or weights).\n",
    "1. Interate over a dataset of inputs.\n",
    "1. Process input through the network. Feed the data forward.\n",
    "1. Compute the loss (how far is the output from being correct/how far off is the output from reality?)\n",
    "1. Propagate gradients back into the networks parameters.\n",
    "1. Update the weights of the NN, using an update rule: weight = weight * (learning_rate * gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my first neural network! October 7th, 2020 2:59am\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution kernel?\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        # 6 input image channels, 16 output channels, 3x3 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # Calculate weights for each layer\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension?\n",
    "        self.fc2 = nn.Linear(120, 84)  # I vaguely remember doing something like this in Deep Learning\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Feeding the inputs forward through the network\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size of the window is a square, you can only specify a single number.\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "         \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # select all dimensions except for the batch dimension. 16?\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 10\n",
      "torch.Size([6, 1, 3, 3])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 576])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Learnable parameters of a model are returned using `net.parameters()`\n",
    "params = list(net.parameters())\n",
    "print(f\"Number of parameters: {len(params)}\")\n",
    "\n",
    "# Each convolution is collapsed on the number of output channels.\n",
    "for i in range(0, 10):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting. Parameters 0 and 2 hold the weights of conv1 and conv2.\n",
    "Layout of returned parameters at index 0 and 2\n",
    "\n",
    "| Parameter | # Output Channels | # Input Image Channels | Row Length of Convolutional Kernel | Colum Length of Convolution Kernel |\n",
    "|----|----|----|----|----|\n",
    "|params[0]|6|1|3|3|\n",
    "|params[2]|16|6|3|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0042,  0.1801,  0.0571, -0.0237, -0.0985, -0.0091,  0.0828, -0.1106,\n",
      "          0.0414,  0.0634]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 1, 32, 32)\n",
    "out = net(input_tensor)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.rand(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn` only supports __mini-batches__.\n",
    "Naturally, `torch.nn` only supports inputs that are a mini-batch of samples. No single samples. \"All or none\".\n",
    "\n",
    "`nn.Conv2d` will accept a 4D Tensor of `nSamples` x `nChannels` X `Height` X `Width`. `n_samples` is the number of mini-batached inputs.\n",
    "- If you only have a single sample use `input_tensor.unsqueeze(0)` to add a fake batch dimension.\n",
    "\n",
    "__Summary__\n",
    "\n",
    "`torch.Tensor` A multi-dimensional array with support for autograd operations like backpropagation via `backward()`.\n",
    "\n",
    "`nn.Module` Neural Network Module. Encapsulates parameters, with helpers to move the parameters GPU, exporting, loading.\n",
    "\n",
    "`nn.Parameter` A quasi-Tensor that is automatically registered as a parameter when assigned as an attribute to a `Module`.\n",
    "\n",
    "`autograd.Function` Implements forward and backward definitions of an autograd operation. (Forward Propagation, Backward Propagation) Tensor operations create at least a single Function node that connects to functions that created a Tensor and encodes its memory. That's where we see grad_fn=Sumback, and Multback, AddBakward\n",
    "\n",
    "\n",
    "## Loss Function\n",
    "A loss function takes the (output(PREDICTION), target) pair of inputs and calculates a value that estimates how much the prediction was off from the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9539, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input_tensor)\n",
    "target = torch.randn(10)  # Create a dummy target to understand the concept\n",
    "target = target.view(1, -1)  # Use the `.view()` function to reshape the target to have the same shape as the output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x000001BDB9BA95B0>\n",
      "<AddmmBackward object at 0x000001BDB9BA1880>\n",
      "<AccumulateGrad object at 0x000001BDB9BA95B0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear \n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU is called AccumulateGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "Use `loss.backward()` to backpropagate the error. Clear the gradients, else gradients will be accumulate with existing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bais.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.base.grad after backward\n",
      "tensor([ 0.0089,  0.0046, -0.0105, -0.0021, -0.0002, -0.0206])\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bais.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.base.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Update the Weights\n",
    "\n",
    "The simplest update rule used in practice is SGD, Stochastic Gradient Descent\n",
    "\n",
    "`weight = weight - gradient * learning_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)  # The weight held in data.sub_ is subtracted from the grad * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = net(input_tensor)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Train a Classifier\n",
    "\n",
    "Source of this [tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c72a334dc1146079993a5a2b339935a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=6,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=6,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship dog car bird frog car\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize The images in CIFAR-10 are of size 3 color channels, 32 pixels x 32 pixels\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Wrap the trainloader into iter() to randomly select 4 images each time this cell is ran.\n",
    "dataiter = iter(trainloader)\n",
    "# .next() loads the next 4 images each time the cell is ran. This is because the batch size is 4. 4 Images per batch.\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%3s' % classes[labels[j]] for j in range(6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 3 input image channels (color), 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 6 input image channels, 16 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Calculate weights for each layer\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5 x 5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # Passes x through the neural network. Forward Propagation.\n",
    "    def forward(self, x):\n",
    "        # Feeding the inputs forward through the network\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # If the size of the window is a square, you can only specify a single number.\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # This function flattens the dimensions of `x` once passed through function `foward(x)`==forward propagation\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # select all dimensions except for the batch dimension. 16?\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.910\n",
      "[1,  4000] loss: 0.912\n",
      "[1,  6000] loss: 0.890\n",
      "[1,  8000] loss: 0.912\n",
      "[2,  2000] loss: 0.903\n",
      "[2,  4000] loss: 0.902\n",
      "[2,  6000] loss: 0.915\n",
      "[2,  8000] loss: 0.901\n",
      "Finished Training, Sir - Jarvis\n"
     ]
    }
   ],
   "source": [
    "# Runs n epochs or training iterations\n",
    "# This is the number of times that network trains on the data. In this case 1 time.\n",
    "for epoch in range(2):\n",
    "    # On each iteration, reset the running_loss to 0.\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero/clear out the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward propagation + backward propagation + optimize\n",
    "        # This is where the neural network predicts what the image labels are. `net()` is my neural network.\n",
    "        outputs = net(inputs)\n",
    "        # The loss function calculates the error between the models predictions an the actual target -> Labels!\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Perform backpropagation so each conv1 layer can 'learn' by updating its weights.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  # Prints the current epoch, the number of minibatches processed, and the loss/error from ground truth.\n",
    "                 (epoch + 1, i + 1, running_loss / 3000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print(\"Finished Training, Sir - Jarvis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train the network on test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# display images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\"GroundTruth: \", ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If an NVIDIA GPU is available use it. Else use the CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# I'm not sure what this syntax means yet.\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "# Let's reload Jarvis :)\n",
    "# We prepare our neural net for test set evaluation\n",
    "net = Net()\n",
    "\n",
    "# Using `net.load_state_dict()` I can load the PATH saved to the current directory. -> './cifar_net_1.pth'\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:   frog   dog   car horse\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(\"Predicted: \", ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 50.57%\n",
      "cuda:0\n",
      "Accuracy of the network on the 10,000 test images: 50.57%\n",
      "cuda:0\n",
      "4.72 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Baseline prediction is {1/len(classes):.0%}\")\n",
    "print(f\"Accuracy of the network on the 10,000 test images: {correct / total:.2%}\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(testloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-175bd7d43ce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-r 1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'device = torch.device(\"cpu\")\\n\\ninputs, labels = data\\ninputs, labels = inputs.to(device), labels.to(device)\\n\\n# Let\\'s reload Jarvis :)\\n# We prepare our neural net for test set evaluation\\nnet = Net()\\n\\n# Using `net.load_state_dict()` I can load the PATH saved to the current directory. -> \\'./cifar_net_1.pth\\'\\nnet.load_state_dict(torch.load(PATH))\\n\\noutputs = net(images)\\n\\n_, predicted = torch.max(outputs, 1)\\n\\nprint(\"Predicted: \", \\' \\'.join(\\'%5s\\' % classes[predicted[j]] for j in range(4)))\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2369\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2371\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2372\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "inputs, labels = data\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "# Let's reload Jarvis :)\n",
    "# We prepare our neural net for test set evaluation\n",
    "net = Net()\n",
    "\n",
    "# Using `net.load_state_dict()` I can load the PATH saved to the current directory. -> './cifar_net_1.pth'\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(\"Predicted: \", ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Baseline prediction is {1/len(classes):.0%}\")\n",
    "print(f\"Accuracy of the network on the 10,000 test images: {correct / total:.2%}\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
