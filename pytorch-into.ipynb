{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n",
    "https://pytorch.org/tutorials/beginner/nlp/pytorch_tutorial.html\n",
    "\n",
    "Notes:\n",
    "- Deep learning uses __tensors__ to perform computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "$\\vec{v}$ to $\\mathcal{T}$\n",
    "\n",
    "https://en.wikiversity.org/wiki/Tensors/Definitions\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "__Tensors__ can be constructed using:\n",
    "1. List of lists\n",
    "1. `pandas` series\n",
    "1. `numpy` 1D-arrays\n",
    "1. List of numbers in `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My first lil' tensor :')\n",
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Tensor from a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Tensor Matrix from:\n",
    "1. List of lists\n",
    "1. List of Series\n",
    "1. `numpy` matrix\n",
    "1. `pandas` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of lists\n",
    "lists = [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]]\n",
    "\n",
    "torch.tensor(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Series\n",
    "a = pd.Series(np.arange(0, 10))\n",
    "\n",
    "torch.tensor((a, a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3745, 3.2861, 1.7952],\n",
       "        [1.9264, 9.5940, 6.1870],\n",
       "        [3.3367, 2.1279, 4.0479]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy matrix\n",
    "matrix_A = np.random.uniform(1, 10, size=(3,3))\n",
    "\n",
    "torch.tensor(matrix_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 38, 93, 65, 64, 61, 15, 60, 81,  2],\n",
       "        [80, 39, 16, 30, 63, 20,  2, 73, 37, 17],\n",
       "        [73, 50, 81, 53, 23, 77, 86, 36, 24,  7],\n",
       "        [96, 15, 97, 69,  5, 42, 29, 46, 71, 83],\n",
       "        [59, 65, 89, 48, 49, 73,  1, 49, 43, 72],\n",
       "        [ 3, 20,  1, 34, 97, 36, 28, 69, 86, 73],\n",
       "        [80, 98, 17, 22, 73, 99, 19, 64, 41, 61],\n",
       "        [86, 27, 94, 52,  7, 65, 22, 86, 19, 92],\n",
       "        [42, 61, 37,  3, 20, 52, 17, 14, 72,  8],\n",
       "        [96, 40, 13, 20, 54, 85, 20, 44, 66, 22]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas matrix\n",
    "matrix_B = pd.DataFrame(\n",
    "    np.random.randint(low=1,high=100,size=(10,10))\n",
    ")\n",
    "\n",
    "# torch.as_tensor(matrix_B) >>> TypeError: not a sequence\n",
    "# torch.tensor(martix_B) >>> TypeError: not a sequence\n",
    "torch.tensor(matrix_B.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a multi-dimensional Tensor from:\n",
    "\n",
    "1. List of lists\n",
    "2. List of Series\n",
    "3. `numpy` matrix\n",
    "4. `pandas` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of lists\n",
    "multi_lists = [[[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]],\n",
    "               [[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]],\n",
    "               [[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]]]\n",
    "\n",
    "Tensor = torch.tensor(multi_lists)\n",
    "Tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy matrix/ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Indexing\n",
    "\n",
    "What is a multi-dimesional (n-D) tensor?\n",
    "\n",
    "1. A multi-dimesional tensor has matrix indicies\n",
    "2. A matrix has vector indicies\n",
    "3. A vector has scalar indicies\n",
    "\n",
    "\n",
    "## Indexing into a Vector\n",
    "Let's look at this visually, starting with the vector we created, $\\vec{v}$ `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(vector.shape)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors, Elements, and Scalars\n",
    "$\\vec{v}$ = \\[0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\]\n",
    "\n",
    "$\\vec{v}$ has a shape of _m_ x _n_ = 10 rows, 1 column\n",
    "\n",
    "__Plain English__:\n",
    "\n",
    "- We have an array with 10 numbers\n",
    "- The shape of the array is 10 rows x 1 column\n",
    "\n",
    "__Explanation__:\n",
    "\n",
    "- We're working with a vector with 10 elements.\n",
    "- The elements are _scalars_ with values 0 - 9.\n",
    "\n",
    "> __Elements__ in _linear algebra_ are also called entries, coefficients, or components.\n",
    ">\n",
    "> * Elements of a vector\n",
    "> * Entries of a vector\n",
    "> * Coefficients of a vector\n",
    "> * Components of a vector\n",
    ">\n",
    "> They all mean the same thing!\n",
    "\n",
    "> To explain this difference between _elements_ and _scalars_, let's imagine you're sitting down to a nice breakfast with your family. \n",
    "\n",
    ">There's pancakes, sausage, toast, yogurt, fruit, bacon, tea, coffee, orange juice, and water. Like a vulture, you circle each platter for the perfect piece and add it to your plate. Once you're finished you take a seat.\n",
    "\n",
    "> 1. Your _plate is the vector_. It holds your delicious breakfast.\n",
    "2. Each piece of fresh food you have on your plate is the _number of elements in your vector_.\n",
    "3. The __name__ of each piece(s) (e.g. 3 strips of bacon, 2 pieces of fruit, 1 dallop of yogurt, 4 pancakes) are your _scalars_!\n",
    "\n",
    ">Food for thought: You have a preference, the pieces on your plate are the direct result of weighted decisions _you make_.\n",
    "\n",
    "> ### Let's setup our vector\n",
    "> How many _elements_ do we have?\n",
    ">-  3 (bacon strips)\n",
    ">- \\+ 2 (pieces of fruit)\n",
    ">- \\+ 1 (dallop of yogurt)\n",
    ">- \\+ 4 (pancakes) \n",
    ">- = 10 (pieces of food)\n",
    " \n",
    ">Let's weight each food item:\n",
    ">- Bacon - 6\n",
    ">- Fruit - 9\n",
    ">- Yogurt - 10\n",
    ">- Pancakes - 11\n",
    "\n",
    ">Let's make our plate:\n",
    ">\n",
    ">$\\vec{plate}$ = \\[6(bacon strip),\n",
    "6(bacon strip),\n",
    "6(bacon strip), 9(fruit), 9(fruit), 10(yogurt), 11(pancake), 11(pancake), 11(pancake), 11(pancake)\\]\n",
    "\n",
    ">Awesome. Let's not forget about our computer's breakfast, I mean _vector_:\n",
    ">\n",
    ">$\\vec{v}$ = \\[6, 6, 6, 9, 9, 10, 11, 11, 11, 11\\]\n",
    "\n",
    "> Help your family with the dishes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Indexing into a vector results in a single value, our scalar.\n",
    "# n is the number of elements in a vector, in our case 10\n",
    "# ith element in vector is equal to v[i] here i=[1-1],....,i=[n-1]\n",
    "# Here we get a scalar.\n",
    "print(vector[0])\n",
    "print(type(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a value, we need to pull the scalar out of the vector.\n",
    "print(vector[0].item())\n",
    "type(vector[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices and Vectors\n",
    "\n",
    "Let's see what our matrix looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2 dimensions\n",
      "(3, 3)\n",
      "[[9.37453347 3.2861392  1.79524279]\n",
      " [1.92636318 9.59396917 6.18704059]\n",
      " [3.33666875 2.1279054  4.04792622]]\n"
     ]
    }
   ],
   "source": [
    "print(type(matrix_A))\n",
    "print(matrix_A.ndim, 'dimensions')\n",
    "print(matrix_A.shape)\n",
    "print(matrix_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing into the Matrix\n",
    "- Whether you index into a matrix by row or column, you will get a vector.\n",
    "> The size of the vector that is returned depends on the shape of the matrix. If a matrix has a shape of (4, 3)\n",
    "> - Indexing by __row__ yields a vector of size 4.\n",
    "> - Indexing by __column__ returns a vector of size 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.37453347 3.2861392  1.79524279]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# Indexing into our matrix using, well, index/bracket notation :D\n",
    "# The bracket notation returns only column values in the first row\n",
    "# print(matrix_A[0]) \n",
    "print(matrix_A[0,:])  # used explicit index notation\n",
    "print(matrix_A[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[3.2861392  9.59396917 2.1279054 ]\n"
     ]
    }
   ],
   "source": [
    "# The bracket notation returns all rows, of the second column.\n",
    "print(matrix_A[:,1].shape)\n",
    "print(matrix_A[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing into a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out our Tensor\n",
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(Tensor.ndim)\n",
    "print(Tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into a Tensor return the first Matrix at index 0!\n",
    "Tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "* Tensors can be created from other numerical datatypes.\n",
    "    * Similar to numpy and pandas, you can specify the datatype when you create a ndarray or dataframe/series.\n",
    "* Most common datatypes used in Tensors are `float` and `long`.\n",
    "\n",
    "\n",
    "# Creating Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_C = np.random.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1479,  0.1754, -0.0624],\n",
       "        [ 1.0879, -0.3806, -0.1507],\n",
       "        [ 0.6763,  0.1481, -0.4151]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A * matrix_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations\n",
    "https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.,  8., 10.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([5., 6., 7.])\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.linspace(1, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cannot concat `torch` dtypes with `numpy` dtypes.\n",
    "``` python\n",
    "torch.cat([tensor_A, matrix_C], 1)\n",
    "#TypeError: expected Tensor as element 1 in argument 0, but got numpy.ndarray\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using torch.as_tensor() to tansform numpy array to a tensor.\n",
    "tensor_C = torch.as_tensor(matrix_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Tensor Join\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6614,  0.2669,  0.0617, -0.2236,  0.6571, -1.0125],\n",
       "        [ 0.6213, -0.4519, -0.1661,  1.7509,  0.8423,  0.9069],\n",
       "        [-1.5228,  0.3817, -1.0276, -0.4442,  0.3881,  0.4040]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like pd.concat(), you can specify the axis you want to join the\n",
    "# tensors on.\n",
    "print(\"Column Tensor Join\")\n",
    "torch.cat([tensor_A, tensor_C], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Tensor Join\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6614,  0.2669,  0.0617],\n",
       "        [ 0.6213, -0.4519, -0.1661],\n",
       "        [-1.5228,  0.3817, -1.0276],\n",
       "        [-0.2236,  0.6571, -1.0125],\n",
       "        [ 1.7509,  0.8423,  0.9069],\n",
       "        [-0.4442,  0.3881,  0.4040]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Row Tensor Join\")\n",
    "torch.cat([tensor_A, tensor_C], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor N-Dimensions: 3\n",
      "Reshaped Tensor N-Dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "# There are 24 elements in this tensor\n",
    "tensor_x = torch.randn(2, 3, 4)\n",
    "\n",
    "# .view() is equivalent of pd.reshape().\n",
    "# Using .view() on a tensor to remove a dimension\n",
    "tensor_x_view = tensor_x.view(2, 12)\n",
    "\n",
    "print('Original Tensor N-Dimensions:', tensor_x.ndim)\n",
    "print('Reshaped Tensor N-Dimensions:', tensor_x_view.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another way to reshape a tensor: torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "# -1 in view will cause torch to infer the dimension.\n",
    "tensor_x_view2 = tensor_x.view(2, -1)\n",
    "print(\"Another way to reshape a tensor:\", tensor_x_view2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graphs and Automatic Differentiation\n",
    "\n",
    "Computation graphs are essential to efficient deep learning programming.\n",
    "- The programmer doesn't need to write the backpropagation\n",
    "Computation graphs shows how your tensors are/were combined to give you the output.\n",
    "- Specifies what parameters were involved in creating a tensor.\n",
    "- Computation graphs can be used to calculate derivatives.\n",
    "> `requires_grad` must be set to `True` in order to calculate derivatives and perform backpropagation.\n",
    ">\n",
    ">\"...All this output tensor knows is its data and shape. It has no idea that it was the sum of two other tensors (it could have been read in from a file, it could be the result of some other operation, etc.)\n",
    ">\n",
    ">If `requires_grad`=`True`, the Tensor object keeps track of how it was created. Lets see it in action.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13., 12., 29., 87., 20.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x0000026CC1805700>\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([6., 9., 4., 3., 8.], requires_grad=True)\n",
    "y = torch.tensor([7., 3., 25., 84., 12.], requires_grad=True)\n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(161., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x0000026CC19A2DF0>\n"
     ]
    }
   ],
   "source": [
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# \"...note if you run this block multiple times, the gradient will\n",
    "# increment. That is because Pytorch accumulates the gradient into\n",
    "# the .grad property, since for many models this is very convenient.\"\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cornerstone Fundamentals\n",
    "##### \\*\\*\\*Crucial for being a successful programmer in deep learning***\n",
    "Tensors \"know\" how they were created when `requires_grad` = `True`\n",
    "\n",
    "### Tensors without Backpropagation: `requires_grad=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4, 4)\n",
    "b = torch.randn(4, 4)\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does Tensor `a` have grad? False\n",
      "Does Tensor `b` have grad? False\n",
      "Does Tensor `c` have grad? False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Does Tensor `a` have grad? {a.requires_grad}\")\n",
    "print(f\"Does Tensor `b` have grad? {b.requires_grad}\")\n",
    "print(f\"Does Tensor `c` have grad? {c.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a tensor is created without setting `requires_grad` = True, tensors created from \"grad-less\" tensors will be unable to perform derivatives. No derivatives, no backpropagation.\n",
    "\n",
    "### Tensors _with_ Backpropagation: `requires_grad=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4100,  0.4085,  0.2579,  1.0950],\n",
       "        [-0.5065,  0.0998, -0.6540,  0.7317],\n",
       "        [-1.4567,  1.6089,  0.0938, -1.2597],\n",
       "        [ 0.2546, -0.5020, -1.0412,  0.7323]], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method `requires_grad_() sets requires_grad = True, inplace.\n",
    "a.requires_grad_()\n",
    "b.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4533,  1.1422,  0.2486, -1.7754],\n",
       "        [-0.0255, -1.0233, -0.5962, -1.0055],\n",
       "        [ 0.4285,  1.4761, -1.7869,  1.6103],\n",
       "        [-0.7040, -0.1853, -0.9962, -0.8313]], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate cells to show `requires_grad_()` changes the Tensors\n",
    "# inplace.\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4100,  0.4085,  0.2579,  1.0950],\n",
       "        [-0.5065,  0.0998, -0.6540,  0.7317],\n",
       "        [-1.4567,  1.6089,  0.0938, -1.2597],\n",
       "        [ 0.2546, -0.5020, -1.0412,  0.7323]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x0000026CBB4B1970>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "c = a + b\n",
    "print(c.grad_fn)  # Our Tensors know how they were created!\n",
    "print(c.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing autograd from Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tensor.detach(), we can remove the values/scalars from\n",
    "# a tensor without its 'memory' (ability to tell how it was created)\n",
    "new_c = c.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# new_c is not as cool as old 'c', it cannot perform backpropagation.\n",
    "\n",
    "# \"In essence, we have broken the Tensor away from its past history\"\n",
    "\n",
    "\n",
    "print(new_c.requires_grad)\n",
    "print(new_c.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# wrap the code block tensor\n",
    "with torch.no_grad():\n",
    "    print((x * 42).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor that is not operated on, changed, transformed inside the body of the `with` statement will be __unchanged__ if `requires_grad=True`.\n",
    "``` python\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "```\n",
    "\\>\\>\\> __True__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series(np.arange(0, 10))\n",
    "\n",
    "# torch.tensor((a, b, c).as_matrix())\n",
    "# torch.cat((a, b, c))\n",
    "\n",
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "np.ndarray(vector) # tensors do not support indexing error.\n",
    "np.array(vector)\n",
    "pd.Series(vector)\n",
    "pd.DataFrame(vector)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.arange(0, 10_000_000).reshape(1000, 100, 100)\n",
    "M = np.arange(0, 10_000_000).reshape(1000, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 ms ± 39.5 µs per loop (mean ± std. dev. of 10 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 1_000\n",
    "1 + T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8 ms ± 407 µs per loop (mean ± std. dev. of 10 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 1_000\n",
    "1 + M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
