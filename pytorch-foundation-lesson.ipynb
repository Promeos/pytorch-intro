{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n",
    "https://pytorch.org/tutorials/beginner/nlp/pytorch_tutorial.html\n",
    "\n",
    "Notes:\n",
    "- Deep learning uses __tensors__ to perform computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "$\\vec{v}$ to $\\mathcal{T}$\n",
    "\n",
    "https://en.wikiversity.org/wiki/Tensors/Definitions\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "__Tensors__ can be constructed using:\n",
    "1. List of lists\n",
    "1. `pandas` series\n",
    "1. `numpy` 1D-arrays\n",
    "1. List of numbers in `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My first lil' tensor :')\n",
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Tensor from a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Tensor Matrix from:\n",
    "1. List of lists\n",
    "1. List of Series\n",
    "1. `numpy` matrix\n",
    "1. `pandas` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of lists\n",
    "lists = [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]]\n",
    "\n",
    "torch.tensor(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Series\n",
    "a = pd.Series(np.arange(0, 10))\n",
    "\n",
    "torch.tensor((a, a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9565, 5.3255, 9.6886],\n",
       "        [8.1861, 8.4726, 5.9775],\n",
       "        [2.4068, 1.3501, 4.7444]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy matrix\n",
    "matrix_A = np.random.uniform(1, 10, size=(3,3))\n",
    "\n",
    "torch.tensor(matrix_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[76, 73, 32, 87, 32, 19, 88, 63, 66, 54],\n",
       "        [82, 61,  3,  2, 81, 96, 22, 33, 18, 72],\n",
       "        [54, 98, 14, 74, 16, 92,  8, 41, 31, 39],\n",
       "        [35, 16, 56, 50, 29, 36,  7, 49, 53, 19],\n",
       "        [11, 93, 86, 83, 39, 89, 58, 69,  6, 83],\n",
       "        [87, 36, 33, 52, 69, 27, 39, 39, 53, 47],\n",
       "        [10, 46, 27, 44, 42, 53, 44, 79, 17, 99],\n",
       "        [64, 33,  4, 97, 91, 25, 48, 27, 78, 58],\n",
       "        [52, 12, 83, 74, 89, 70,  7, 86, 90, 61],\n",
       "        [71, 71, 37, 89, 12, 22,  9, 95, 23, 82]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas matrix\n",
    "matrix_B = pd.DataFrame(\n",
    "    np.random.randint(low=1,high=100,size=(10,10))\n",
    ")\n",
    "\n",
    "# torch.as_tensor(matrix_B) >>> TypeError: not a sequence\n",
    "# torch.tensor(martix_B) >>> TypeError: not a sequence\n",
    "torch.tensor(matrix_B.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a multi-dimensional Tensor from:\n",
    "\n",
    "1. List of lists\n",
    "2. List of Series\n",
    "3. `numpy` matrix\n",
    "4. `pandas` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of lists\n",
    "multi_lists = [[[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]],\n",
    "               [[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]],\n",
    "               [[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]]]\n",
    "\n",
    "Tensor = torch.tensor(multi_lists)\n",
    "Tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Series\n",
    "a = pd.Series(np.arange(1, 10))\n",
    "b = pd.Series(np.arange(1, 10))\n",
    "c = pd.Series(np.arange(1, 10))\n",
    "d = pd.Series(np.arange(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([a, b, c, d],\n",
    "             dtype=torch.float64,\n",
    "             requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy matrix/ndarray\n",
    "e = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(e, dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(16).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pandas matrix\n",
    "torch.tensor(pd.DataFrame(np.arange(16).reshape(4, 4)),\n",
    "             dtype=torch.float64,\n",
    "             requires_grad=True)\n",
    "\n",
    "# Pandas DataFrames cannot be used to create tensor object.\n",
    "# You must extract the values from the dataframe using `.values()`\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-75-22b40f39bc99> in <module>\n",
    "      1 # pandas matrix\n",
    "----> 2 torch.tensor(pd.DataFrame(np.arange(16).reshape(4, 4)),\n",
    "      3              dtype=torch.float64,\n",
    "      4              requires_grad=True)\n",
    "\n",
    "TypeError: not a sequence\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Indexing\n",
    "\n",
    "What is a multi-dimesional (n-D) tensor?\n",
    "\n",
    "1. A multi-dimesional tensor has matrix indicies\n",
    "2. A matrix has vector indicies\n",
    "3. A vector has scalar indicies\n",
    "\n",
    "\n",
    "## Indexing into a Vector\n",
    "Let's look at this visually, starting with the vector we created, $\\vec{v}$ `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(vector.shape)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors, Elements, and Scalars\n",
    "$\\vec{v}$ = \\[0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\]\n",
    "\n",
    "$\\vec{v}$ has a shape of _m_ x _n_ = 10 rows, 1 column\n",
    "\n",
    "__Plain English__:\n",
    "\n",
    "- We have an array with 10 numbers\n",
    "- The shape of the array is 10 rows x 1 column\n",
    "\n",
    "__Explanation__:\n",
    "\n",
    "- We're working with a vector with 10 elements.\n",
    "- The elements are _scalars_ with values 0 - 9.\n",
    "\n",
    "> __Elements__ in _linear algebra_ are also called entries, coefficients, or components.\n",
    ">\n",
    "> * Elements of a vector\n",
    "> * Entries of a vector\n",
    "> * Coefficients of a vector\n",
    "> * Components of a vector\n",
    ">\n",
    "> They all mean the same thing!\n",
    "\n",
    "> To explain this difference between _elements_ and _scalars_, let's imagine you're sitting down to a nice breakfast with your family. \n",
    "\n",
    ">There's pancakes, sausage, toast, yogurt, fruit, bacon, tea, coffee, orange juice, and water. Like a vulture, you circle each platter for the perfect piece and add it to your plate. Once you're finished you take a seat.\n",
    "\n",
    "> 1. Your _plate is the vector_. It holds your delicious breakfast.\n",
    "2. Each piece of fresh food you have on your plate is the _number of elements in your vector_.\n",
    "3. The __name__ of each piece(s) (e.g. 3 strips of bacon, 2 pieces of fruit, 1 dallop of yogurt, 4 pancakes) are your _scalars_!\n",
    "\n",
    ">Food for thought: You have a preference, the pieces on your plate are the direct result of weighted decisions _you make_.\n",
    "\n",
    "> ### Let's setup our vector\n",
    "> How many _elements_ do we have?\n",
    ">-  3 (bacon strips)\n",
    ">- \\+ 2 (pieces of fruit)\n",
    ">- \\+ 1 (dallop of yogurt)\n",
    ">- \\+ 4 (pancakes) \n",
    ">- = 10 (pieces of food)\n",
    " \n",
    ">Let's weight each food item:\n",
    ">- Bacon - 5\n",
    ">- Fruit - 9\n",
    ">- Yogurt - 10\n",
    ">- Pancakes - 11\n",
    "\n",
    ">Let's make our plate:\n",
    ">\n",
    ">$\\vec{plate}$ = \\[6(bacon strip),\n",
    "6(bacon strip),\n",
    "6(bacon strip), 9(fruit), 9(fruit), 10(yogurt), 11(pancake), 11(pancake), 11(pancake), 11(pancake)\\]\n",
    "\n",
    ">Awesome. Let's not forget about our computer's breakfast, I mean _vector_:\n",
    ">\n",
    ">$\\vec{v}$ = \\[5, 5, 5, 9, 9, 10, 11, 11, 11, 11\\]\n",
    "\n",
    "> Help your family with the dishes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Indexing into a vector results in a single value, our scalar.\n",
    "# n is the number of elements in a vector, in our case 10\n",
    "# ith element in vector is equal to v[i] here i=[1-1],....,i=[n-1]\n",
    "# Here we get a scalar.\n",
    "print(vector[0])\n",
    "print(type(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a value, we need to pull the scalar out of the vector.\n",
    "print(vector[0].item())\n",
    "type(vector[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices and Vectors\n",
    "\n",
    "Let's see what our matrix looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2 dimensions\n",
      "(3, 3)\n",
      "[[9.95652199 5.32553101 9.68859943]\n",
      " [8.18606239 8.47262493 5.97747344]\n",
      " [2.4068148  1.35010209 4.74439807]]\n"
     ]
    }
   ],
   "source": [
    "print(type(matrix_A))\n",
    "print(matrix_A.ndim, 'dimensions')\n",
    "print(matrix_A.shape)\n",
    "print(matrix_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing into the Matrix\n",
    "- Whether you index into a matrix by row or column, you will get a vector.\n",
    "> The size of the vector that is returned depends on the shape of the matrix. If a matrix has a shape of (4, 3)\n",
    "> - Indexing by __row__ yields a vector of size 4.\n",
    "> - Indexing by __column__ returns a vector of size 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.95652199 5.32553101 9.68859943]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# Indexing into our matrix using, well, index/bracket notation :D\n",
    "# The bracket notation returns only column values in the first row\n",
    "# print(matrix_A[0]) \n",
    "print(matrix_A[0,:])  # used explicit index notation\n",
    "print(matrix_A[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[5.32553101 8.47262493 1.35010209]\n"
     ]
    }
   ],
   "source": [
    "# The bracket notation returns all rows, of the second column.\n",
    "print(matrix_A[:,1].shape)\n",
    "print(matrix_A[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing into a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out our Tensor\n",
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(Tensor.ndim)\n",
    "print(Tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into a Tensor return the first Matrix at index 0!\n",
    "Tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "* Tensors can be created from other numerical datatypes.\n",
    "    * Similar to numpy and pandas, you can specify the datatype when you create a ndarray or dataframe/series.\n",
    "* Most common datatypes used in Tensors are `float` and `long`.\n",
    "\n",
    "\n",
    "# Creating Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_C = np.random.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5005, -0.1047,  0.1011],\n",
       "        [ 0.4217,  0.2843, -0.1316],\n",
       "        [-0.5932,  0.5813,  1.3796]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A * matrix_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations\n",
    "https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.,  8., 10.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([5., 6., 7.])\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.linspace(1, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cannot concat `torch` dtypes with `numpy` dtypes.\n",
    "``` python\n",
    "torch.cat([tensor_A, matrix_C], 1)\n",
    "#TypeError: expected Tensor as element 1 in argument 0, but got numpy.ndarray\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using torch.as_tensor() to tansform numpy array to a tensor.\n",
    "tensor_C = torch.as_tensor(matrix_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Tensor Join\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6614,  0.2669,  0.0617, -0.7568, -0.3922,  1.6395],\n",
       "        [ 0.6213, -0.4519, -0.1661,  0.6787, -0.6292,  0.7920],\n",
       "        [-1.5228,  0.3817, -1.0276,  0.3895,  1.5229, -1.3426]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like pd.concat(), you can specify the axis you want to join the\n",
    "# tensors on.\n",
    "print(\"Column Tensor Join\")\n",
    "torch.cat([tensor_A, tensor_C], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Tensor Join\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6614,  0.2669,  0.0617],\n",
       "        [ 0.6213, -0.4519, -0.1661],\n",
       "        [-1.5228,  0.3817, -1.0276],\n",
       "        [-0.7568, -0.3922,  1.6395],\n",
       "        [ 0.6787, -0.6292,  0.7920],\n",
       "        [ 0.3895,  1.5229, -1.3426]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Row Tensor Join\")\n",
    "torch.cat([tensor_A, tensor_C], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor N-Dimensions: 3\n",
      "Reshaped Tensor N-Dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "# There are 24 elements in this tensor\n",
    "tensor_x = torch.randn(2, 3, 4)\n",
    "\n",
    "# .view() is equivalent of pd.reshape().\n",
    "# Using .view() on a tensor to remove a dimension\n",
    "tensor_x_view = tensor_x.view(2, 12)\n",
    "\n",
    "print('Original Tensor N-Dimensions:', tensor_x.ndim)\n",
    "print('Reshaped Tensor N-Dimensions:', tensor_x_view.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another way to reshape a tensor: torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "# -1 in view will cause torch to infer the dimension.\n",
    "tensor_x_view2 = tensor_x.view(2, -1)\n",
    "print(\"Another way to reshape a tensor:\", tensor_x_view2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graphs and Automatic Differentiation\n",
    "\n",
    "Computation graphs are essential to efficient deep learning programming.\n",
    "- The programmer doesn't need to write the backpropagation\n",
    "Computation graphs shows how your tensors are/were combined to give you the output.\n",
    "- Specifies what parameters were involved in creating a tensor.\n",
    "- Computation graphs can be used to calculate derivatives.\n",
    "> `requires_grad` must be set to `True` in order to calculate derivatives and perform backpropagation.\n",
    ">\n",
    ">\"...All this output tensor knows is its data and shape. It has no idea that it was the sum of two other tensors (it could have been read in from a file, it could be the result of some other operation, etc.)\n",
    ">\n",
    ">If `requires_grad`=`True`, the Tensor object keeps track of how it was created. Lets see it in action.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13., 12., 29., 87., 20.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000002298D0B8EE0>\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([6., 9., 4., 3., 8.], requires_grad=True)\n",
    "y = torch.tensor([7., 3., 25., 84., 12.], requires_grad=True)\n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(161., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x000002298D0A1CA0>\n"
     ]
    }
   ],
   "source": [
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# \"...note if you run this block multiple times, the gradient will\n",
    "# increment. That is because Pytorch accumulates the gradient into\n",
    "# the .grad property, since for many models this is very convenient.\"\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cornerstone Fundamentals\n",
    "##### \\*\\*\\*Crucial for being a successful programmer in deep learning***\n",
    "Tensors \"know\" how they were created when `requires_grad` = `True`\n",
    "\n",
    "### Tensors without Backpropagation: `requires_grad=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4, 4)\n",
    "b = torch.randn(4, 4)\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does Tensor `a` have grad? False\n",
      "Does Tensor `b` have grad? False\n",
      "Does Tensor `c` have grad? False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Does Tensor `a` have grad? {a.requires_grad}\")\n",
    "print(f\"Does Tensor `b` have grad? {b.requires_grad}\")\n",
    "print(f\"Does Tensor `c` have grad? {c.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a tensor is created without setting:\n",
    "```python\n",
    "requires_grad=True\n",
    "```\n",
    "Tensors created from \"grad-less\" tensors will inherit the inability to perform auto differentiation i.e. unable to perform derivatives. No derivatives, no backpropagation. No backprop no neural networks.\n",
    "\n",
    "### Tensors _with_ Backpropagation: `requires_grad=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4100,  0.4085,  0.2579,  1.0950],\n",
       "        [-0.5065,  0.0998, -0.6540,  0.7317],\n",
       "        [-1.4567,  1.6089,  0.0938, -1.2597],\n",
       "        [ 0.2546, -0.5020, -1.0412,  0.7323]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method `requires_grad_() sets requires_grad = True, inplace.\n",
    "a.requires_grad_()\n",
    "b.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4533,  1.1422,  0.2486, -1.7754],\n",
       "        [-0.0255, -1.0233, -0.5962, -1.0055],\n",
       "        [ 0.4285,  1.4761, -1.7869,  1.6103],\n",
       "        [-0.7040, -0.1853, -0.9962, -0.8313]], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate cells to show `requires_grad_()` changes the Tensors\n",
    "# inplace.\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4100,  0.4085,  0.2579,  1.0950],\n",
       "        [-0.5065,  0.0998, -0.6540,  0.7317],\n",
       "        [-1.4567,  1.6089,  0.0938, -1.2597],\n",
       "        [ 0.2546, -0.5020, -1.0412,  0.7323]], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002298D0DA040>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "c = a + b\n",
    "print(c.grad_fn)  # Our Tensors know how they were created!\n",
    "print(c.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing autograd from Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tensor.detach(), we can remove the values/scalars from\n",
    "# a tensor without its 'memory' (ability to tell how it was created)\n",
    "new_c = c.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# new_c is not as cool as old 'c', it cannot perform backpropagation.\n",
    "\n",
    "# \"In essence, we have broken the Tensor away from its past history\"\n",
    "\n",
    "\n",
    "print(new_c.requires_grad)\n",
    "print(new_c.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# wrap the code block tensor\n",
    "with torch.no_grad():\n",
    "    print((x * 42).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor that is not operated on, changed, or transformed inside the body of the `with` statement will remain __unchanged__ i.e. will retain the ability to perform backprop if `requires_grad=True`. I think this situation may be rare.\n",
    "``` python\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "```\n",
    "\\>\\>\\> __True__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Code from the cell above.\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series(np.arange(0, 10))\n",
    "\n",
    "# torch.tensor((a, b, c).as_matrix())\n",
    "# torch.cat((a, b, c))\n",
    "\n",
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "np.ndarray(vector) # tensors do not support indexing error.\n",
    "np.array(vector)\n",
    "pd.Series(vector)\n",
    "pd.DataFrame(vector)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.arange(0, 10_000_000).reshape(1000, 100, 100)\n",
    "M = np.arange(0, 10_000_000).reshape(1000, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.9 ms ± 1.4 ms per loop (mean ± std. dev. of 10 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# This was worth it! I am eternally grateful!\n",
    "%%timeit -r 10 -n 1_000\n",
    "1 + T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 ms ± 483 µs per loop (mean ± std. dev. of 10 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 1_000\n",
    "1 + M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
